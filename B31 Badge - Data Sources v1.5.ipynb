{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d8eb4a6",
   "metadata": {},
   "source": [
    "# Data Badge: Data Sources\n",
    "\n",
    "\n",
    "### - In this notebook:\n",
    "\n",
    "- [Reading local CSV files](#local-files)\n",
    "- [Reading CSV files from a URL](#reading-url)\n",
    "- [Reading JSON files](#reading-json)\n",
    "- [Reading from database files](#reading-databases)\n",
    "- [Making API calls](#api-calls)\n",
    "- Mini-diary ⭐️⭐️⭐️❓\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba95e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c07e0",
   "metadata": {},
   "source": [
    "<a id=\"local-files\"></a>\n",
    "# 1. Reading Local CSV Files\n",
    "\n",
    "#### What are CSV (comma separated values) files?\n",
    "\n",
    "These basically look like simplified Excel. First line of the file contains names of columns, and then each next line is a set of values for those columns. Values are separated by commas.\n",
    "\n",
    "`\n",
    "name, age, department\n",
    "Pim, 34, ER\n",
    "Jannet, 54, Oncology\n",
    "Aoife, 25, Oncology\n",
    "`\n",
    "\n",
    "Notice you cannot skip any values, since the only indicator of what data means is in which order it is. So for example, if you do not know one person's name you can't just write:\n",
    "\n",
    "```Natasha, ER```\n",
    "\n",
    "...becuase it would treat ER as their age. (second value means second column). Instead sometimes you will see missing data just skipped with a missing value (nothing between commas) like this:\n",
    "\n",
    "```Natasha,,ER```\n",
    "\n",
    "Local files are files that are on your computer, often stored in a 'data' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527905e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import some data from a local CSV file using Pandas.\n",
    "\n",
    "# If we did not specify index_col, index would be 0,1,2,3,... but this data already has a good index \n",
    "nursing_home_residents = pd.read_csv(\"./data/nursing_home_residents.csv\")\n",
    "nursing_home_residents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be98d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we could create an index, but in this dataset none of the columns is uniquely identifying a row\n",
    "# Instead what is unique is the combination of date, statistic and CA (council area)\n",
    "\n",
    "# So E.G. If the date was a unique row item, we could use index_col to specify index\n",
    "# nursing_home_residents = pd.read_csv(\"./data/nursing_home_residents.csv\", index_col='Date')\n",
    "# nursing_home_residents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727eff5a",
   "metadata": {},
   "source": [
    "<a id=\"reading-url\"></a>\n",
    "# 2. Reading CSV Files from a URL\n",
    "\n",
    "### Online files use EXACTLY the same code\n",
    "\n",
    "This is just so amazing. If the 'filename' you use in read_csv starts with http... it will be simply loaded from the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62192981",
   "metadata": {},
   "outputs": [],
   "source": [
    "nursing_home_residents = pd.read_csv(\"https://www.opendata.nhs.scot/dataset/75cca0a9-780d-40e0-9e1f-5f4796950794/resource/139f61d8-a87d-419d-b7af-31f555a60c89/download/file3_mean_median_age_years.csv\")\n",
    "nursing_home_residents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851336d",
   "metadata": {},
   "source": [
    "<a id=\"reading-json\"></a>\n",
    "# 3. Reading JSON Files\n",
    "\n",
    "#### What are JSON files? (key-value pairs, like Python dictionary)\n",
    "\n",
    "These will be very familiar to you. Lists are indicated by [ ] and key value pairs (separated by : colon) are enclosed in { }\n",
    "\n",
    "```\n",
    "[\n",
    "    {'name':'Pim', 'age':34, 'department':'Oncology'},\n",
    "    {'name':'Jannet', 'age':54, 'department':'Oncology'},\n",
    "    {'name':'Aoife', 'age':25, 'department':'Oncology'}\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65327777",
   "metadata": {},
   "source": [
    "Sometimes JSON is simple but other times it can be complex (e.g. very nested (things, within things, within things))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5486e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_staff = pd.read_json(\"./data/simple.json\")\n",
    "simple_staff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58297e65",
   "metadata": {},
   "source": [
    "But if the file is 'nested' as in, it contains things within things, we need to tell Pandas how we want it read.\n",
    "Notice that in file `nested_deeper.json` the staff members are no longer at the top level. Also that there is a List of information ('shifts') inside of each staff member. It is no longer obvious how to change it into an Excel spreadsheet format that is so easy for CSV.\n",
    "\n",
    "We will need to guide Pandas deeper into the datastructure... and say I care about: `inside of hospitals, the staff collection`.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"requested_date\": \"01012025\",\n",
    "  \"server_info\": {\"location\": \"europe-2\", \"timezone\": \"GMT\"},\n",
    "  \"hospitals\": [\n",
    "    {\n",
    "      \"hospital_name\":\"Western General\",\n",
    "      \"location\":{\"city\":\"Edinburgh\", \"board\":\"NHS Lothian\"},\n",
    "      \"staff\":[\n",
    "        {\"name\":\"Pim\", \"age\":34, \"department\":\"ER\", \"shifts\": [\"day\"]},\n",
    "        {\"name\":\"Jannet\", \"age\":54, \"department\":\"Oncology\", \"shifts\": [\"day\", \"night\"]},\n",
    "        {\"name\":\"Aoife\", \"age\":25, \"department\":\"Oncology\",  \"shifts\": [\"night\"]}\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"hospital_name\":\"Raigmore Hospital\",\n",
    "      \"location\":{\"city\":\"Inverness\", \"board\":\"NHS Highland Board\"},\n",
    "      \"staff\":[\n",
    "        {\"name\":\"Pat\", \"age\":24, \"department\":\"ER\", \"shifts\": [\"day\"]},\n",
    "        {\"name\":\"Jimmy\", \"age\":44, \"department\":\"ER\", \"shifts\": [\"day\", \"night\"]},\n",
    "        {\"name\":\"Siobhan\", \"age\":45, \"department\":\"ER\",  \"shifts\": [\"day\", \"night\"]}\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "  \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d30a9",
   "metadata": {},
   "source": [
    "If we do not specify what we mean, we'll get something like this: (not very useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c9fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nested_staff = pd.read_json(\"./data/nested_deeper.json\")\n",
    "# nested_staff\n",
    "\n",
    "## this will throw an error because Panda doesn;t know part is important (staff!)\n",
    "## ValueError: Mixing dicts with non-Series may lead to ambiguous ordering. \n",
    "## we commented this out as the error is massive :D Uncomment and have a look, but then comment it back out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b40e44b",
   "metadata": {},
   "source": [
    "So we need to specify things:\n",
    "\n",
    "- in data jump into the `hospitals`, and then start parsing\n",
    "- staff members are nested under key `staff`\n",
    "- then inside each staff member I want all of their data, but also some 'meta information'. see code below and try to figure out what it does.\n",
    "\n",
    "What we do here is:\n",
    "\n",
    "1. We Load the file, and then create another dataframe by 'interpreting' just one of the columns items (`hospitals`), then each item in the sub-collection the `staff`\n",
    "\n",
    "This is a simple way if your data is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/nested_deeper.json\", 'r') as file:\n",
    "    nested_all_data = json.load(file)  # Load the JSON data from the file\n",
    "\n",
    "# Normalize the 'staff' array into a DataFrame\n",
    "df_staff = pd.json_normalize(\n",
    "    nested_all_data['hospitals'],\n",
    "    record_path=[\"staff\"], \n",
    "    meta= [\"hospital_name\", [\"location\", \"city\"]] )\n",
    "df_staff\n",
    "# bracket-usage challange: how would you add the info of the \"board\" as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c60153",
   "metadata": {},
   "source": [
    "Notice the `shifts` column has data as lists. We can use `explode()` to expand the shifts column into separate rows. Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b42ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'shifts' column. This will make the data long (a bit). There's another way, see below.\n",
    "df_staff_long = df_staff.explode(\"shifts\")\n",
    "df_staff_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa7eae",
   "metadata": {},
   "source": [
    "And if you prefer dummy variables (useful for some visualisations and machine learning tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ecbff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn data into binarry dummies: 1 if present, 0 if not-present \n",
    "dummies = pd.get_dummies(df_staff['shifts'].explode()).groupby(level=0).sum()\n",
    "dummies = dummies.add_prefix('shift.')\n",
    "shifts_df_dummies = pd.concat([dummies, df_staff], axis = 1)\n",
    "shifts_df_dummies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5afc617",
   "metadata": {},
   "source": [
    "There are more examples of normalising and converting nested JSON <a href=\"https://pandas.pydata.org/docs/dev/reference/api/pandas.json_normalize.html\">here</a> and <a href=\"https://saturncloud.io/blog/how-to-convert-nested-json-to-pandas-dataframe-with-specific-format/#converting-nested-json-to-pandas-dataframe\">here</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e6d67",
   "metadata": {},
   "source": [
    "<a id=\"reading-databases\"></a>\n",
    "# 4. Reading from Database files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de88e1d2",
   "metadata": {},
   "source": [
    "### A Quick Explanation of Relational Databases\n",
    "\n",
    "Relational databases organise data into tables with rows and columns, like interconnected spreadsheets.\n",
    "\n",
    "Each table represents a specific entity and relationships between tables are established using primary and foreign keys, ensuring data integrity and reducing redundancy.\n",
    "\n",
    "SQL is the standard language used to interact with these databases, allowing for efficient querying, manipulation, and management of large, complex datasets, making them essential for structured data storage and analysis.\n",
    "\n",
    "Here we will use a **different flavour of sql** than in the video. This flavour, called `sqlite3` is simpler when we are working on **local db file** (rather than an online database which we connect to using the internet).\n",
    "\n",
    "Notice we use a `cursor` which is the **active connection to the database**. You can think of a cursor as a mouse pointer on your computer, or a needle on a old vinyl record - it is pointing at the database, and you can give commands to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8ffbec52-a652-4c27-a752-79722a203f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to db file called my_example_db.sqlite (will create it if file it doens't exist)\n",
    "connection = sqlite3.connect(\"./data/students_pets_db.sqlite\")\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8f4dac0c-7c0c-470d-86d8-6b1d7986df53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fd87d4ce9c0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will delete all database data you created before! \n",
    "cursor.execute(\"DROP TABLE IF EXISTS Levels;\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS Students;\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS Pets;\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS Owners;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f25f573d-b565-42f3-b0ce-8c57572b3d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fd87d4ce9c0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for now the database is empty, so let's create some tables \n",
    "# Levels\n",
    "create_levels_sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Levels (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    name TEXT,\n",
    "    short_name TEXT)\n",
    "\"\"\"\n",
    "cursor.execute(create_levels_sql)\n",
    "\n",
    "# Students\n",
    "create_students_sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Students (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    name TEXT,\n",
    "    age INTEGER,\n",
    "    level_id INTEGER)\n",
    "\"\"\"\n",
    "cursor.execute(create_students_sql)\n",
    "\n",
    "# Pets\n",
    "create_pets_sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Pets (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    name TEXT)\n",
    "\"\"\"\n",
    "cursor.execute(create_pets_sql)\n",
    "\n",
    "# Owners\n",
    "create_owners_sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Owners (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    student_id INTEGER,\n",
    "    pet_id INTEGER\n",
    "    )\n",
    "\"\"\"\n",
    "cursor.execute(create_owners_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8ad56fb1-022f-4cea-9391-1680ed2493a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Postgraduate', 'PG'), (2, 'Undergraduate', 'UG')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok, let's add some data:\n",
    "cursor.execute(\"DELETE FROM Levels\")\n",
    "cursor.execute(\"INSERT INTO Levels (id, name, short_name) VALUES (1, 'Postgraduate', 'PG' )\")\n",
    "cursor.execute(\"INSERT INTO Levels (id, name, short_name) VALUES (2, 'Undergraduate', 'UG')\")\n",
    "cursor.execute(\"SELECT * FROM Levels\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "87eab2a4-f89a-47a6-aa17-cff49159a453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'cat'), (2, 'dog'), (3, 'fish')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok, let's add some data:\n",
    "cursor.execute(\"DELETE FROM Pets\")\n",
    "cursor.execute(\"INSERT INTO Pets (id, name) VALUES (1, 'cat')\")\n",
    "cursor.execute(\"INSERT INTO Pets (id, name) VALUES (2, 'dog')\")\n",
    "cursor.execute(\"INSERT INTO Pets (id, name) VALUES (3, 'fish')\")\n",
    "cursor.execute(\"SELECT * FROM Pets\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3d9390f0-d861-4532-a450-edba5d181c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Pat', 34, 1), (2, 'Natasha', 64, 2), (3, 'Pip', 54, 2), (4, 'Jo', 37, 1)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok, let's add some data:\n",
    "cursor.execute(\"DELETE FROM Students\")\n",
    "cursor.execute(\"INSERT INTO Students (id, name, age, level_id) VALUES (1, 'Pat', 34, 1)\")\n",
    "cursor.execute(\"INSERT INTO Students (id, name, age, level_id) VALUES (2, 'Natasha', 64, 2)\")\n",
    "cursor.execute(\"INSERT INTO Students (id, name, age, level_id) VALUES (3, 'Pip', 54, 2)\")\n",
    "cursor.execute(\"INSERT INTO Students (id, name, age, level_id) VALUES (4, 'Jo', 37, 1)\")\n",
    "cursor.execute(\"SELECT * FROM Students\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "21ba672e-0873-477b-a6f6-bc543b45689f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 1),\n",
       " (2, 1, 1),\n",
       " (3, 1, 2),\n",
       " (4, 2, 1),\n",
       " (5, 2, 1),\n",
       " (6, 2, 1),\n",
       " (7, 3, 1),\n",
       " (8, 3, 3),\n",
       " (9, 4, 1),\n",
       " (10, 4, 3)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok, let's add some data:\n",
    "cursor.execute(\"DELETE FROM Owners\")\n",
    "# Pat has two cats and a dog\n",
    "cursor.execute(\"INSERT INTO Owners (student_id, pet_id) VALUES (1, 1)\")\n",
    "cursor.execute(\"INSERT INTO Owners ( student_id, pet_id) VALUES (1, 1)\")\n",
    "cursor.execute(\"INSERT INTO Owners ( student_id, pet_id) VALUES (1, 2)\")\n",
    "# Natasha has three cats\n",
    "cursor.execute(\"INSERT INTO Owners (student_id, pet_id) VALUES (2, 1)\")\n",
    "cursor.execute(\"INSERT INTO Owners ( student_id, pet_id) VALUES (2, 1)\")\n",
    "cursor.execute(\"INSERT INTO Owners ( student_id, pet_id) VALUES (2, 1)\")\n",
    "# Pip and Jo have a fish and cat each\n",
    "cursor.execute(\"INSERT INTO Owners (student_id, pet_id) VALUES (3, 1)\")\n",
    "cursor.execute(\"INSERT INTO Owners (student_id, pet_id) VALUES (3, 3)\")\n",
    "cursor.execute(\"INSERT INTO Owners ( student_id, pet_id) VALUES (4, 1)\")\n",
    "cursor.execute(\"INSERT INTO Owners ( student_id, pet_id) VALUES (4, 3)\")\n",
    "\n",
    "cursor.execute(\"SELECT * FROM Owners\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447b808a-96fe-475d-9189-d557fcbb9287",
   "metadata": {},
   "source": [
    "Let's run a very simple query:\n",
    "\n",
    "bewlo `*` means **all columns**, but you could also specify only the columns you want. It would look like this `SELECT Name, Age FROM Students`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dbf6daca-8cd5-4b3e-b7ae-6f363799a725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Pat', 34, 1), (4, 'Jo', 37, 1)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"SELECT * FROM Students WHERE Students.level_id = 1\")\n",
    "rows = cursor.fetchall()\n",
    "rows\n",
    "# have a peak at the data above, where we created tables data, what is going on here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791804cb-759c-4842-9a5f-75b467d3269d",
   "metadata": {},
   "source": [
    "And here is a more complex query with joins. if you have not seen it before, tripple \" creates a special type of string where you can use new lines. This is very useful for readability!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0d2ee2e0-06fe-455b-884d-6c8c025faafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natasha', 'cat'),\n",
       " ('Natasha', 'cat'),\n",
       " ('Natasha', 'cat'),\n",
       " ('Pip', 'cat'),\n",
       " ('Pip', 'fish')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query = \"\"\"\n",
    "SELECT Students.name, Pets.name \n",
    "FROM Pets\n",
    "LEFT JOIN Owners ON Pets.id = Owners.pet_id\n",
    "LEFT JOIN Students ON Students.id = Owners.student_id\n",
    "JOIN Levels ON Students.level_id = Levels.id\n",
    "WHERE Levels.short_name = 'UG'\n",
    "\"\"\"\n",
    "cursor.execute(sql_query)\n",
    "rows = cursor.fetchall()\n",
    "rows\n",
    "# have a peak at the data above, where we created tables data, what is going on here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3596c783-34b8-4200-8325-223c40971c1a",
   "metadata": {},
   "source": [
    "#### But how do we then turn this database result info dataframes?\n",
    "\n",
    "Luckilly (as always!) Pandas has a function for that! We pass into that function the full SQL string, and the `connection variable` (not the cursor! Pandas will operate the cursor by itself).\n",
    "\n",
    "Have a look below how it will look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bfeab679-d797-4a64-b12d-2cfa831cdd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natasha</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natasha</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natasha</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pip</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pip</td>\n",
       "      <td>fish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  name\n",
       "0  Natasha   cat\n",
       "1  Natasha   cat\n",
       "2  Natasha   cat\n",
       "3      Pip   cat\n",
       "4      Pip  fish"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query = \"\"\"\n",
    "SELECT Students.name, Pets.name\n",
    "FROM Pets\n",
    "LEFT JOIN Owners ON Pets.id = Owners.pet_id\n",
    "LEFT JOIN Students ON Students.id = Owners.student_id\n",
    "JOIN Levels ON Students.level_id = Levels.id\n",
    "WHERE Levels.short_name = 'UG'\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(sql_query, connection)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf06c7-33c5-4f7d-ba66-f6676df7e889",
   "metadata": {},
   "source": [
    "Oh no! but both columns have the same name! (`'name'`). That's really not useful in Pandas!\n",
    "\n",
    "**Giving nicknames to tables and columns** is a very useful technique where you can give a short name to things, like\n",
    "\n",
    "```\n",
    "SELECT department.name dept_name \n",
    "FROM HospitalDepartment department\n",
    "```\n",
    "\n",
    "instead of \n",
    "\n",
    "```\n",
    "SELECT HospitalDepartment.name \n",
    "FROM HospitalDepartment\n",
    "```\n",
    "\n",
    "This is especially useful when we want to have meaningful column names in pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4a9dbfa0-ec3a-465e-8839-fa3f188e8b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_name</th>\n",
       "      <th>pet_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natasha</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natasha</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natasha</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pip</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pip</td>\n",
       "      <td>fish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  student_name pet_name\n",
       "0      Natasha      cat\n",
       "1      Natasha      cat\n",
       "2      Natasha      cat\n",
       "3          Pip      cat\n",
       "4          Pip     fish"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query = \"\"\"\n",
    "SELECT Students.name student_name, Pets.name  pet_name\n",
    "FROM Pets\n",
    "LEFT JOIN Owners ON Pets.id = Owners.pet_id\n",
    "LEFT JOIN Students ON Students.id = Owners.student_id\n",
    "JOIN Levels ON Students.level_id = Levels.id\n",
    "WHERE Levels.short_name = 'UG'\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(sql_query, connection)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a57ae0-7df4-488b-83cd-2f7057ab34a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "888ed90f-27f6-4563-92a8-e0ca2e753eb9",
   "metadata": {},
   "source": [
    "Finally, when you are done working with a database, it is a good idea to close the connections. This is very important when many users access the databse at the same time, as it might have a limit of maximum consecutive connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0c455d5c-219b-45aa-8a07-9ab36d65c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close conenction\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf71cdd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1c742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7506e08",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fda1d27",
   "metadata": {},
   "source": [
    "<a id=\"api-calls\"></a>\n",
    "# 5. Making API Calls\n",
    "\n",
    "API (Application Programming Interface) is an alternative way of accessing data and can be very powerful. There are a plethora of APIs available on the internet - some free, some that you have to pay for and some that require you to sign up for a key.\n",
    "\n",
    "NHS Scotland Opendata has most of its datasets available as APIs. You can search for a dataset and click on the green \"Data API\" button to get the url. <a href=\"https://www.opendata.nhs.scot/organization/isd\">click here for PHS Health and care datasets</a>\n",
    "\n",
    "## Requests and Responses\n",
    "\n",
    "When we create an API call in Python, we are making a **request**. Most of the time, this is a GET request i.e. we're asking the URL to get us some data. The server that lives at the URL address will respond with a **response**.\n",
    "\n",
    "## What is a URL?\n",
    "\n",
    "In order to request data from an API we need to know the URL (Uniform Resource Locator). This is essentially the address of a resource on the internet. Think of it like a street address for a website or a specific file. It tells us where to find what you're looking for. \n",
    "\n",
    "\n",
    "## JSON again!\n",
    "\n",
    "Usually, APIs will respond with the data in JSON format. The tricky part, as ever with JSON, is examining the structure of the data so that you can drill down into the data to get the parts that are relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e422fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use an example of a fun API for illustration purposes - the Pokemon API (Pokemon are little cartoon characters)\n",
    "# Here's the URL for accessing the data of the top 20 Pokemon\n",
    "\n",
    "url = 'https://pokeapi.co/api/v2/pokemon'\n",
    "\n",
    "# https: This is the protocol used to access the data (hypertext transfer protocol secure)\n",
    "# pokeapi.co: This is the domain name of the website hosting the API\n",
    "# api/v2: This is the path to the API endpoint\n",
    "# pokemon: This is the resource we are accessing\n",
    "# you can think of it as a bit like a file system on your computer. Each part of the URL is like a folder or file.\n",
    "\n",
    "\n",
    "# we can use the requests library to make a GET request to the URL\n",
    "import requests\n",
    "\n",
    "pokemon_df = None\n",
    "\n",
    "try:\n",
    "    response = requests.get(url)  # Make the GET request\n",
    "    response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "    pokemon_data = response.json()  # Parse the JSON response\n",
    "    pokemon_df  = pd.DataFrame.from_dict(pokemon_data['results'])\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "pokemon_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have a DataFrame with the names and URLs of the first 20 Pokemon!\n",
    "# We could loop through the names and display them\n",
    "for counter, name in enumerate(pokemon_df['name'], start=1): # Use enumerate to get a counter AND name\n",
    "    print(f\"Pokemon number {counter}: {name}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74510245",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Or we can use the URL for the \"bulbasaur\" Pokemon to get more information about it\n",
    "bulbasaur_url = pokemon_df.loc[pokemon_df['name'] == 'bulbasaur', 'url']\n",
    "bulbasaur_url\n",
    "\n",
    "# We can use the requests library to make a GET request to the URL\n",
    "bulbasaur_data = None\n",
    "\n",
    "try:\n",
    "    response = requests.get(bulbasaur_url.iloc[0])  # Make the GET request\n",
    "    response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "    bulbasaur_data = response.json()\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error: {e}\") \n",
    "\n",
    "# Let's see what we got. It's a dict!\n",
    "print(f\"Bulbasaur data type: {type(bulbasaur_data)}\")\n",
    "\n",
    "# Let's see what keys we have in the dict\n",
    "bulbasaur_data.keys()\n",
    "\n",
    "# We could create a DataFrame from the abilities key for example\n",
    "bulbasaur_abilities_df = pd.DataFrame(bulbasaur_data['abilities'])\n",
    "bulbasaur_abilities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecbf9aa",
   "metadata": {},
   "source": [
    "## Final Tasks:\n",
    "\n",
    "1. Practice unbundling data. Take a variables you created before, and undbundle/parse them the same way we unbundled hospital staff in examples above.\n",
    "2. Look at two ways of acquiring the same data (api request, and SQL reqiest), and find simmilarities and differences between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4363987b",
   "metadata": {},
   "source": [
    "\n",
    "### Task 1: `bulbasaur_data` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edcfa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can code here, here's a starting variable. We care about the abilities of this pokemon.\n",
    "import pprint as pp\n",
    "\n",
    "pp.pprint(bulbasaur_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f27867",
   "metadata": {},
   "source": [
    "### Challenge 2: getting online data via simple API and via online SQL\n",
    "\n",
    "There is no 'task as such' below. But have a look at what the code does, and see how much you understand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736a36e",
   "metadata": {},
   "source": [
    "\n",
    "#### Part 1: Simple API\n",
    "\n",
    "Let's make an API request to get the data from the NHS Scotland website about nursing home residents\n",
    "The data is in json format.\n",
    "We can use our json knowledge to turn the correct part of the json data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4059161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pprint as pp\n",
    "\n",
    "url = 'https://www.opendata.nhs.scot/api/3/action/datastore_search?resource_id=139f61d8-a87d-419d-b7af-31f555a60c89'  \n",
    "\n",
    "nursing_home_residents_df = None\n",
    "\n",
    "try:\n",
    "    response = requests.get(url)  # Make the GET request\n",
    "    response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "    data = response.json()  # Parse the JSON response\n",
    "    # HERE WRITE YOUR CODE\n",
    "    nursing_home_residents_df  = pd.DataFrame(data['result']['records']) # We are interested in the 'records' part of the data\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "# to start you off let's print the data format.\n",
    "# pp.pprint(data['result']['records']) #if you're interested how raw data looks, uncomment this\n",
    "nursing_home_residents_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3aea11",
   "metadata": {},
   "source": [
    "#### Part 2: Simple online sql\n",
    "\n",
    "This is a very interesting mix of API and SQL: you can pass in SQL code as part of your url, like\n",
    "\n",
    "`https://somewebsite.com?sql=SELECT name FROM students`\n",
    "\n",
    "We will build the SQL, then send it to the API to get interpreted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc6d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql = f'SELECT \"HBName\", \"HB\" FROM \"652ff726-e676-4a20-abda-435b98dd7bdc\"'\n",
    "# sql = f'SELECT * FROM \"652ff726-e676-4a20-abda-435b98dd7bdc\"' # if you want all columns, use *\n",
    "\n",
    "website_url = \"https://www.opendata.nhs.scot/api/3/action/datastore_search_sql\"\n",
    "\n",
    "final_url = f\"{website_url}?sql={sql}\"\n",
    "\n",
    "response = requests.get(final_url)\n",
    "# pp.pprint(response.json()) #if you're interested how raw data looks, uncomment this\n",
    "hb_lookup = pd.DataFrame(response.json()['result']['records'])\n",
    "hb_lookup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f17ea",
   "metadata": {},
   "source": [
    "## ⭐️⭐️⭐️💥 What you learned in this session: Three stars and a wish \n",
    "**In your own words** write in your Learn diary:\n",
    "\n",
    "- 3 things you yould like to remember from this badge\n",
    "- 1 thing you wish to understand better in the future or a question you'd like to ask\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
